{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlTrain = \"LogisticData.csv\"\n",
    "df = pd.read_csv(urlTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = df.shape[1]\n",
    "X = df.iloc[:,0:column-1]\n",
    "Y = df.iloc[:,column-1:column]\n",
    "G=pd.DataFrame()\n",
    "#groundTruth = df.iloc[:,column-1:column]\n",
    "G['Y'] = df.iloc[:,column-1:column]\n",
    "groundTruth = G['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame((X-X.mean())/X.std())\n",
    "X.insert(0, 'Ones', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n",
    "Y.head()\n",
    "groundTruth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 3\n"
     ]
    }
   ],
   "source": [
    "X = np.matrix(X)  \n",
    "Y = np.matrix(Y)\n",
    "m, n = np.shape(X)\n",
    "print(m , n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a sigmoid function and return the value tht has been calculated for z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the cost function for Logistic Regression. Remember to calculate the sigmoid values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(beta, X, Y):\n",
    "    tempbeta = np.matrix(beta)\n",
    "    result= np.sum(np.multiply(-Y, np.log(sigmoid(X * tempbeta.T)))-np.multiply((1 - Y), np.log(1 - sigmoid(X * tempbeta.T))))/len(X)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a gradient function that takes in beta, X and Y as parameters and returns the best betas and cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X, Y, beta, alpha, iters):\n",
    "    '''\n",
    "    Compute the gradient descent function.\n",
    "    Return beta and the cost array.\n",
    "    '''\n",
    "    cost = np.zeros(iters)\n",
    "    m, n = np.shape(X)\n",
    "    #beta = np.matrix(beta)\n",
    "    i=0\n",
    "    for i in range(iters):\n",
    "        Err=sigmoid(np.dot(X, beta)) - Y\n",
    "        #print beta, i\n",
    "        j=0\n",
    "        for j in range(n):\n",
    "            tempBeta=beta[j]\n",
    "            tempBeta=tempBeta-((alpha/m ) * np.sum(np.dot(Err, X[:,j])))\n",
    "            beta[j]=tempBeta\n",
    "        cost[i]=costFunction(beta,X,Y)\n",
    "        \n",
    "    #print beta[0], i\n",
    "    return beta, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#please try different values to see the results, but alpha=0.01 and iters=10000 are suggested.\n",
    "beta = np.zeros(n)\n",
    "alpha = 0.01\n",
    "iters = 10000\n",
    "resultDescent = gradientDescent(X, Y, beta, alpha, iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta From Gradient Descent :  [ 4.05465108e-01 -8.21565038e-18 -2.04281037e-17]\n"
     ]
    }
   ],
   "source": [
    "print(\"Beta From Gradient Descent : \" ,resultDescent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(beta, X, Y):\n",
    "    '''\n",
    "    This function returns the gradient calucated.\n",
    "    '''\n",
    "    #for i in range(parameters):\n",
    "    #####\n",
    "    #grad[i] =\n",
    "    m, n = np.shape(X)\n",
    "    grad = np.zeros(n)\n",
    "    Err = sigmoid(np.dot(X, beta)) - Y\n",
    "    for j in range(n):\n",
    "        term = np.multiply(Err, X[:,j])\n",
    "        grad[j] = np.sum(term) / m\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the parameters given functions to compute the cost and the gradients. We can use SciPy's optimization to do the same thing. Define a variable result and complete the functions by adding the right parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the optimised betas are stored in the first index of the result variable\n",
    "beta = np.zeros(n)\n",
    "result = opt.fmin_tnc(func=costFunction , x0=beta , fprime =gradient , args=(X,Y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.54810212, 4.33189095, 3.86604543]), 83, 1)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(bestBeta, X): \n",
    "    '''\n",
    "    This function returns a list of predictions calculated from the sigmoid using the best beta.\n",
    "    '''\n",
    "    probability = sigmoid(np.dot(X, bestBeta))\n",
    "    p, q= probability.shape\n",
    "    #print p , q\n",
    "    Res = []\n",
    "    for x in range(q):\n",
    "        if probability[0,x]>=0.5:\n",
    "            Res.append(1)\n",
    "        else:\n",
    "            Res.append(0)\n",
    "    return Res, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Beta :  [1.54810212 4.33189095 3.86604543]\n",
      "Cost for Best Beta :  0.20645819114071567\n"
     ]
    }
   ],
   "source": [
    "bestBeta = result[0] \n",
    "print(\"Best Beta : \",bestBeta)\n",
    "print(\"Cost for Best Beta : \",costFunction(bestBeta,X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(prediction, ground1):\n",
    "    '''\n",
    "    Return the computed confusion matrix.\n",
    "    '''\n",
    "    return pd.crosstab( ground1,prediction, rownames=['True'], colnames=['Predicted'], margins=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(groundTruth, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(groundTruth)):\n",
    "        if groundTruth[i] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(groundTruth))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the confusionMatrix function and print the confusion matrix as well as the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0   1\n",
      "True             \n",
      "0          35   5\n",
      "1           5  55\n",
      "90.0\n",
      "accuracy =  90.0\n"
     ]
    }
   ],
   "source": [
    "#The final outputs that we need for this portion of the lab are conf and acc. Copy conf and acc in a .txt file.\n",
    "#Please write a SHORT report and explain these results. Include the explanations for both logistic and linear regression\n",
    "#in the same PDF file. \n",
    "\n",
    "groundTruth1=groundTruth.as_matrix()\n",
    "#print groundTruth1\n",
    "predictions = predict(bestBeta, X)\n",
    "predictionVal=predictions[0]\n",
    "ProbVal=predictions[1]\n",
    "predictionVal=np.array(predictionVal)\n",
    "y_actu = pd.Series(groundTruth)\n",
    "y_pred = pd.Series(predictionVal)\n",
    "conf = confusionMatrix(y_pred,y_actu)\n",
    "#print y_actu\n",
    "print(conf)\n",
    "acc = getAccuracy(groundTruth1, predictionVal)\n",
    "print(acc)\n",
    "print('accuracy = ',(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
